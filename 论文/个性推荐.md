# 推荐

## 评价指标

### NDCG@k(Normalized Discounted Cumulative Gain)

#### 公式

$$\begin{equation}
\text{DCG@k} = \sum_{i=1}^{k} \frac{2^{rel_i} - 1}{\log_2(i+1)}
\end{equation}
$$

$$\begin{equation}
\text{IDCG@k} = \sum_{i=1}^{|\text{ideal}|} \frac{2^{rel_i} - 1}{\log_2(i+1)}
\end{equation}$$

$$\begin{equation}
\text{NDCG@k} = \frac{\text{DCG@k}}{\text{IDCG@k}}
\end{equation}$$

#### 解释

##### 术语

1. **Cumulative Gain (CG)：** 累积增益，指的是在一个排名列表中，从顶部到特定位置k的项目的相关性得分的总和。这是一个衡量搜索或推荐系统有效性的基础指标。
2. **Discounted Cumulative Gain (DCG)：** 折扣累积增益。由于排名列表中较高位置的项目通常比较低位置的项目更重要，因此DCG在计算时给予靠前位置的项目更高的权重。具体来说，每个项目的相关性得分会被其在排名列表中的位置的对数函数所折扣。
3. **@k：** 指的是只考虑排名列表中前k个项目。这个限制反映了用户通常只会关注搜索结果或推荐列表的前几项。
4. **Normalized (NDCG)：** 归一化折扣累积增益。DCG的值依赖于相关性得分的分布和排名列表的长度，这使得不同查询或不同系统间的直接比较变得困难。为了解决这个问题，NDCG通过将DCG除以一个理想情况（即最佳排名顺序）下的最大可能DCG（称为IDCG）来进行归一化。

##### 合理性

1. **为何使用 $\sum_{i=1}^k\frac{2^{rel_i}−1}{log_2(i+1)}$：** 这个公式的目的是放大高相关性项目的权重。通过指数函数，即使是相对较小的相关性分数差异也会在计算中放大，从而更强调排名列表顶部的高相关项目。

2. **为何使用 $log⁡_2(i+1)$：** 这个对数函数用于折扣远离顶部位置的项目的权重，反映了一个事实：用户更可能关注排名列表的前几项。使用对数函数意味着排名靠前的项目相比排名靠后的项目会获得更大的权重，但这种权重随着排名位置的下降而逐渐减少。
    

#### 举例

假设有一个搜索结果的相关性评分如下（分数范围是0到3）： 第1个项目的相关性分数为3（非常相关） 第2个项目的分数为2（相关） 第3个项目的分数为0（不相关） 第4个项目的分数为1（稍微相关） 我们计算NDCG@3（只考虑前3个项目）：

$$\begin{equation}
\text{DCG@3} = \frac{2^3 - 1}{\log_2(1 + 1)} + \frac{2^2 - 1}{\log_2(2 + 1)} + \frac{2^0 - 1}{\log_2(3 + 1)}
\end{equation}
$$

假设理想情况下的前3个项目的相关性分数分别是3，3，2，则 IDCG@3 的公式为：  

$$\begin{equation}
\text{IDCG@3} = \frac{2^3 - 1}{\log_2(1 + 1)} + \frac{2^3 - 1}{\log_2(2 + 1)} + \frac{2^2 - 1}{\log_2(3 + 1)}
\end{equation}$$

最后：

$$\begin{equation}
\text{NDCG@3} = \frac{\text{DCG@3}}{\text{IDCG@3}}
\end{equation}
$$

在数据集中就是对每个样本计算，最后取平均值。

### HR@k(Hit Rate)

#### 公式

$$\text{HR@k} = \frac{\text{Number of queries with at least one relevant item in top-k}}{\text{Total number of queries}}
$$

#### 举例

假设有5次独立的查询，每次查询都返回k个结果，我们想计算HR@3。如果在这5次查询中，有3次查询的至少一个相关项目出现在前3个推荐中，那么 HR@3 = 3/5 = 0.6。这表明在60%的查询中，至少有一个相关项目出现在前3个推荐中。这个指标反映了推荐系统在前k个项目中“命中”相关内容的能力。

在数据集中就是把每个样本看作一次查询，看命中了多少次。Du, Fangrui. 《A Prompt-Based Approach for Discovering Prerequisite Relations among Concepts》, 2023年.