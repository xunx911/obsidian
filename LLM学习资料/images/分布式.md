数据并行：每张GPU上一份模型参数，并行训练
模型并行：一共一份模型参数，每张GPU负责计算不同部分

# DDP
[PyTorch 多卡分布式训练 – CodeTalks (howardlau.me)](https://howardlau.me/programming/pytorch-distributed-data-parallel.html)
逻辑上是个环形结构，n张卡，每张卡上有自己那部分数据的梯度，传递n-1次，一张卡上得到了总梯度，平均后再传递n-1次给到其他卡，使得模型权重统一。

DeepSpeed
>[arxiv.org/pdf/1910.02054](https://arxiv.org/pdf/1910.02054) 
 
[详解 DeepSpeed Zero 的各个 Stage 状态及日常使用_deepspeed zero stage-CSDN博客](https://blog.csdn.net/m0_51341794/article/details/137369288)
Stage 0:DDP
Stage 1: