数据并行：每张GPU上一份模型参数，并行训练
模型并行：一共一份模型参数，每张GPU负责计算不同部分

# DDP
[PyTorch 多卡分布式训练 – CodeTalks (howardlau.me)](https://howardlau.me/programming/pytorch-distributed-data-parallel.html)
[手把手推导Ring All-reduce的数学性质 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/504957661)
逻辑上是个环形结构，n张卡，每张卡上有自己那部分数据的梯度，传递n-1次，一张卡上得到了总梯度，平均后再传递n-1次给到其他卡，使得模型权重统一。

# DeepSpeed 
[详解 DeepSpeed Zero 的各个 Stage 状态及日常使用 | Code & Coffee (ckblogs.cn)](https://ckblogs.cn/posts/dl/DeepSpeed.html#%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%E6%9C%80%E4%BD%B3%E6%80%A7%E8%83%BD%E7%9A%84zero-stage%E5%92%8C-offloads%E2%9A%93%EF%B8%8E)
- Stage 0:DDP
- Stage 1:优化器状态分割到所有设备上
- Stage 2:1+梯度分割到所有设备上
- Stage 3:2+模型参数分割到所有设备上
- offload_param：将模型参数offload到cpu上

# 模型参数量计算
[【LLM指北】五、参数量、计算量FLOPS推导 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/676113501)
[大模型的参数量是如何计算的 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/692319408)

# 模型显存占用计算
