# 举例的数字都是随便说的

# 基础知识

## 转换流程

![[Pasted image 20240220114949.png]]
抖音没有曝光和点击,因为只能下滑看到一条视频

## 消费指标

![[Pasted image 20240220115204.png]]
不能把点击率作为唯一的优化指标,不然骗点击的标题会泛滥
追求短期消费指标是有意义的,但并不是衡量推荐系统好坏的根本指标(竭泽而渔,用户可能很快失去兴趣,而提高多样性虽然不会提升点击率,但可以提升用户粘性)

## 北极星指标

![[Pasted image 20240220115858.png]]
最关键的指标
用户规模(简单易懂,强相关)
消费与点击率冲突时,例如把多样性做好,用户点击率下降了但是使用了更长的时间,完全ok
发布(冷启动)

## 实验流程

![[Pasted image 20240220120802.png]]
小流量AB测试:对照组和实验组,判断新策略是否显著优于旧策略,如果是则加大流量,最终推全

# 推荐系统的链路

![[Pasted image 20240220121658.png]]
- 召回:用户刷新小红书时,系统调用几十条召回通道,每条通道召回几十到几百篇笔记,一共取回几千篇笔记
- 粗排:用规模小的机器学习模型排序和截断
- 精排:大规模神经网络模型打分,排序截断(小红书不截断)
- 重排:根据精排分数和多样性分数随机抽样得到几十篇笔记,然后把相似内容打散,并且插入广告和运营内容

## 召回通道

![[Pasted image 20240220122347.png]]
召回后还要过滤(例如不喜欢的笔记不喜欢的作者等)

## 重排

![[Pasted image 20240220122651.png]]
主要是考虑多样性,还要把相似的内容打散
![[Pasted image 20240220123018.png]]
抽样的依据:精排分数,多样性

## 粗排 精排

![[Pasted image 20240220122938.png]]

## 总结

![[Pasted image 20240220123114.png]]粗排时也会有一些规则,保证进入精排的笔记具有多样性
重排的规则非常复杂

# A/B测试

离线实验结果有收益,线上未必
![[Pasted image 20240220123422.png]]

## 随机分桶

![[Pasted image 20240220123609.png]]![[Pasted image 20240220123618.png]]每个桶不同的策略/参数

## 分层实验

目标:解决流量不够用的问题
![[Pasted image 20240220123844.png]]
![[Pasted image 20240220123905.png]]
一般来说不同层的实验不会对另一层造成影响,所以是正交
举例
![[Pasted image 20240220124024.png]]![[Pasted image 20240220124216.png]]不同的召回实验不能同时作用于一个用户身上
![[Pasted image 20240220124255.png]]![[Pasted image 20240220142607.png]]

## Holdout机制

![[Pasted image 20240220142950.png]]

## 实验推全 & 反转实验

![[Pasted image 20240220151612.png]]![[Pasted image 20240220151634.png]]
![[Pasted image 20240220151622.png]]![[Pasted image 20240220151710.png]]

## 总结

![[Pasted image 20240220151753.png]]

# 召回

## ItemCF

![[Pasted image 20240220163747.png]]
![[Pasted image 20240220152047.png]]从用户的行为中挖掘物品的相似性
![[Pasted image 20240220152158.png]]![[Pasted image 20240220152204.png]]![[Pasted image 20240220152256.png]]

### 完整流程

![[Pasted image 20240220160903.png]]![[Pasted image 20240220161040.png]]
⽤索引，离线计算量⼤，线上计算量⼩

## Swing召回通道(ItemCF变体)

### ItemCF的不足

![[Pasted image 20240220163349.png]]假设两篇不相关的笔记恰巧分享到了一个vx群,导致一些用户同时交互过这两篇笔记,系统就会误判

### Swing模型

![[Pasted image 20240220163909.png]]![[Pasted image 20240220163917.png]]

### 总结

![[Pasted image 20240220163933.png]]

## UserCF

![[Pasted image 20240220164133.png]]![[Pasted image 20240221145714.png]]![[Pasted image 20240221145722.png]]
越热门的物品应该影响越小
![[Pasted image 20240221150012.png]]![[Pasted image 20240221150021.png]]

### 完整流程

![[Pasted image 20240221150151.png]]
![[Pasted image 20240221150234.png]]
## 矩阵补充
![[Pasted image 20240221160442.png]]![[Pasted image 20240221160458.png]]![[Pasted image 20240221160519.png]]![[Pasted image 20240221160536.png]]![[Pasted image 20240221160615.png]]![[Pasted image 20240221160712.png]]![[Pasted image 20240221160725.png]]![[Pasted image 20240221160824.png]]![[Pasted image 20240221160922.png]]
![[Pasted image 20240221161105.png]]线上实时计算不现实->如何加速最近邻查找避免暴力枚举
### 近似最近邻查找
几亿个物品只做几万次内积
![[Pasted image 20240221161250.png]]![[Pasted image 20240221163202.png]]给物品向量划分区域,每个区域用一个单位向量表示,建立索引,作为key,能取回区域中的所有点  
![[Pasted image 20240221163424.png]]
先找最近的区域,再计算区域内的点即可
### 总结
![[Pasted image 20240221163510.png]]![[Pasted image 20240221163524.png]]

## 双塔模型
![[Pasted image 20240221163651.png]]用户离散特征:例如喜欢的话题,所在的城市,性别等,每个特征单独用一个embedding层
用户连续特征:例如金额等
![[Pasted image 20240221163821.png]]
与矩阵补充相比,双塔模型使用了更多特征
![[Pasted image 20240221163928.png]]
### 训练
![[Pasted image 20240221164031.png]]
#### 正负样本的选择
![[Pasted image 20240221164112.png]]
负样本的选择比较讲究,看论文
#### pointwise
![[Pasted image 20240221164216.png]]
#### pairwise
![[Pasted image 20240221164349.png]]
![[Pasted image 20240221164413.png]]![[Pasted image 20240221164449.png]]
m是超参数,需要调
![[Pasted image 20240221171044.png]]
#### listwise
![[Pasted image 20240221171740.png]]![[Pasted image 20240223103247.png]]
### 总结
![[Pasted image 20240223103449.png]]
![[Pasted image 20240223112538.png]]
前期融合,通常是排序,双塔是后期融合
## 正负样本
选对正负样本,作用大于改进模型结构
### 正样本
![[Pasted image 20240223112914.png]]