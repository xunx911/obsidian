# 损失函数
## CrossEntropyLoss
对于二分类问题，交叉熵损失可以定义为：
$$L = -\frac{1}{N} \sum_{i=1}^{N} [y_i \log(\hat{y}_i) + (1 - y_i) \log(1 - \hat{y}_i)]
$$
其中：

- $N$ 是样本数量。
- $y_i$ 是样本 $i$ 的真实标签（0或1）。
- $\hat{y}_i$ 是模型预测样本 $i$为正类的概率。
对于多分类问题，交叉熵损失的定义扩展为：$$L = -\frac{1}{N} \sum_{i=1}^{N} \sum_{c=1}^{C} y_{i,c} \log(\hat{y}_{i,c})$$
